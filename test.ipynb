{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import wandb\n",
    "import pickle\n",
    "from src.utility.constants import *\n",
    "from src.utility.util import load_data\n",
    "import pandas as pd\n",
    "from src.heuristic.parsing import parse_heuristic\n",
    "from dask.distributed import Client, LocalCluster, wait\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from cross_validation import cross_validation\n",
    "import time\n",
    "from dask import delayed\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster()  # Launches a scheduler and workers locally\n",
    "client = Client(cluster)\n",
    "print(client.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the map-elites table\n",
    "with open(\"artifacts/map-elites-v1/tables.pkl\", 'rb') as f:\n",
    "    tables = pickle.load(f)\n",
    "\n",
    "# Get unique heuristics\n",
    "heuristics, _ = tables.get_stored_data(strip_nan=True)\n",
    "heuristics = list(map(lambda h: parse_heuristic(h, dask=True), heuristics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def delayed_load_data(file):\n",
    "    df = pd.read_parquet(file)\n",
    "    df.columns = list(map(lambda col: NORMALIZED_COLUMN_NAMES_MAPPING[col] if col in NORMALIZED_COLUMN_NAMES_MAPPING else col, df.columns))\n",
    "    return df\n",
    "\n",
    "# Load parquet files\n",
    "dfs = []\n",
    "for file in COMBINED_DATA_FILES:\n",
    "    dfs.append(delayed_load_data(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed(nout=2)\n",
    "def delayed_execute_heuristic(df, heuristics):\n",
    "    new_cols = {str(h): h.execute(df) for h in heuristics}\n",
    "    new_df = df.assign(**new_cols)\n",
    "    x_cols = NORMALIZED_COLUMN_NAMES + list(new_cols.keys())\n",
    "    return new_df[x_cols], new_df[CLASSES_2_Y_COLUMN]\n",
    "\n",
    "Xs = [None for _ in dfs]\n",
    "ys = [None for _ in dfs]\n",
    "\n",
    "# Execute heuristics\n",
    "for i, df in enumerate(dfs):\n",
    "    Xs[i], ys[i] = delayed_execute_heuristic(df, heuristics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def delayed_mean(df):\n",
    "    return df.mean()\n",
    "\n",
    "@delayed\n",
    "def delayed_variance(df):\n",
    "    return df.var()\n",
    "\n",
    "@delayed\n",
    "def delayed_pooled_mean_and_var(means, variances, lens):\n",
    "    means = np.array(means)\n",
    "    variances = np.array(variances)\n",
    "    lens = np.array(lens)[:, np.newaxis]\n",
    "    return (\n",
    "        np.sum(means * lens, axis=0) / np.sum(lens),\n",
    "        np.sum((lens - 1) * variances, axis=0) / (np.sum(lens) - 1)\n",
    "    )\n",
    "\n",
    "lens = [df.shape[0] for df in Xs]\n",
    "means = [delayed_mean(df) for df in Xs]\n",
    "variances = [delayed_variance(df) for df in Xs]\n",
    "data = delayed_pooled_mean_and_var(means, variances, lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82,)\n",
      "[8.12441901e+04 2.12826046e+11 8.00222458e+01 1.96536822e+02\n",
      " 9.91264316e+09 9.91264316e+09 5.25733927e-05 7.90771298e-02\n",
      " 1.64346635e-01 8.23133936e-02 8.00495741e-02 1.08195738e-01\n",
      " 1.47793183e-06 7.28257273e-07 8.20427430e-02 4.40277311e-01\n",
      " 1.07004854e-01 5.16275329e+03 1.05874712e+05 4.59074739e-02\n",
      " 5.20630637e-02 1.30662402e-04 2.14193362e-08 6.42580123e-08\n",
      " 4.09306725e-05 1.49935373e-07 2.44547454e-01 1.67007849e-01\n",
      " 1.71354430e-06 6.61813965e-05 1.36916240e-01 1.12674480e-04\n",
      " 1.12674480e-04 6.82932528e+06 1.95147021e+04 2.74607318e+05\n",
      " 5.80766703e+04 2.57074373e+04 5.83458514e+04 2.90610834e+14\n",
      " 6.71008769e-01 7.44520624e+01 5.14242597e+04 1.04788145e+11\n",
      " 5.42891800e-02 4.43871485e+02 5.42891800e-02 3.71812410e+01\n",
      " 3.08392869e-02 1.01125675e+00 4.28749174e+01 4.29052640e-01\n",
      " 1.05874712e+05 4.22541387e+01 3.71812410e+01 4.35468537e+06\n",
      " 4.36242947e-01 4.90584295e+01 1.08195738e-01 4.35463634e+06\n",
      " 1.46546321e-01 7.71974831e-02 5.01385737e+01 6.00393736e+00\n",
      " 8.71439702e-02 4.39742092e+01 4.57350986e+01 5.24430990e+01\n",
      " 1.96536822e+02 1.13979506e+07 6.06759030e-01 4.09544618e-01\n",
      " 4.77909222e+01 4.86126573e-01 1.25976381e+07 3.80721460e+07\n",
      " 4.16908661e-02 1.48699954e+00 4.18152697e-01 1.01125675e+00\n",
      " 3.50427589e+01 3.71812410e+01]\n"
     ]
    }
   ],
   "source": [
    "means, vars = data.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_jobs=-1, warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def delayed_normalize(df, mu, std):\n",
    "    return (df - mu) / std\n",
    "\n",
    "@delayed\n",
    "def delayed_train(X, y, model):\n",
    "    return model.fit(X, y)\n",
    "\n",
    "@delayed\n",
    "def delayed_predict(X, model):\n",
    "    return model.predict(X)\n",
    "\n",
    "@delayed\n",
    "def delayed_scores(y_true, y_pred):\n",
    "    # Get accuracy, precision, recall, and f1 score\n",
    "    return pd.Series([accuracy_score(y_true, y_pred), precision_score(y_true, y_pred), recall_score(y_true, y_pred), f1_score(y_true, y_pred)], index=['accuracy', 'precision', 'recall', 'f1'])\n",
    "\n",
    "@delayed\n",
    "def delayed_mean_scores(scores):\n",
    "    return pd.concat(scores, axis=1).T.mean()\n",
    "\n",
    "# Train model\n",
    "scores = []\n",
    "for X, Y in zip(Xs, ys):\n",
    "    X = delayed_normalize(X, means, vars ** 0.5)\n",
    "    model = delayed_train(X, Y, model)\n",
    "\n",
    "# model = model.compute()\n",
    "\n",
    "# Test model\n",
    "for X, Y in zip(Xs, ys):\n",
    "    X = delayed_normalize(X, means, vars ** 0.5)\n",
    "    y_pred = delayed_predict(X, model)\n",
    "    scores.append(delayed_scores(Y, y_pred))\n",
    "\n",
    "scores = delayed_mean_scores(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
